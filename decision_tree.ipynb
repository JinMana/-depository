{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_shan(dataset):\n",
    "    '''\n",
    "    计算某个特征的熵\n",
    "    '''\n",
    "    data_len = len(dataset)\n",
    "    kind_class = {}\n",
    "    shan = 0.0\n",
    "    #取dataset每一行\n",
    "    for dataline in dataset:\n",
    "        #取每一行最后一个数\n",
    "        feature_one = dataline[-1] \n",
    "        kind_class[feature_one] = kind_class.get(feature_one, 0) + 1\n",
    "        \n",
    "    for key in kind_class:   #获取的是key值\n",
    "        prob = float(kind_class[key]) / data_len\n",
    "        shan -= prob * math.log(prob, 2)\n",
    "    return shan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset():\n",
    "    dataset = [[1,1,'yes'], [1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "    #是这两个feature的名字\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, axis, value):\n",
    "    '''\n",
    "    功能：去除数据集中axis那一列的值，返回剩下的值\n",
    "    dataset:数据集\n",
    "    axis:某一列，如0 1 2\n",
    "    value:值，如0 1 \n",
    "    '''\n",
    "    retDataset = []\n",
    "    for data in dataset:\n",
    "        if(data[axis] == value):    #有的str类型，可以用==\n",
    "            reduceFeature = data[:axis]    #这两行代码就是为了去掉axis这一列，而取他的左右两列\n",
    "            reduceFeature.extend(data[axis+1:])\n",
    "            retDataset.append(reduceFeature)\n",
    "    return retDataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset(dataset, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择最好的特征\n",
    "def choose_best_method(dataset):\n",
    "    '''\n",
    "    选择信息增益最大的那个特征的下标\n",
    "    '''\n",
    "    data_len = len(dataset[0])-1\n",
    "    #dataset的初始熵\n",
    "    base_shan = cal_shan(dataset)\n",
    "    #信息增益\n",
    "    gain_shan = 0.0\n",
    "    #新的熵\n",
    "    new_shan = 0.0\n",
    "    #信息增益最大\n",
    "    best_gain_shan = 0.0\n",
    "    #熵最大的那个特征\n",
    "    best_feature = -1\n",
    "    \n",
    "    for i in range(data_len):\n",
    "        #获取到dataset第一列的所有数，第二列的所有数\n",
    "        #[1, 1, 1, 0, 0]\n",
    "        #[1, 1, 0, 1, 1]\n",
    "        #取该特征的所有数\n",
    "        feature_list = [example[i] for example in dataset]\n",
    "        #只能获取一行\n",
    "#         feature_list = dataset[i]\n",
    "        unique_val = set(feature_list)  #{0, 1}\n",
    "        for value in unique_val:\n",
    "            retDataset = split_dataset(dataset, i, value)\n",
    "            prob = len(retDataset) / float(len(dataset))    #浮点数\n",
    "            new_shan += prob * cal_shan(retDataset)\n",
    "            \n",
    "        gain_shan = base_shan - new_shan   #上面那一行和下面这一行是信息增益,刚才的错误是信息增益写错，写成new_shan - base_shan\n",
    "        if(gain_shan > best_gain_shan):\n",
    "            best_gain_shan = gain_shan\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature = choose_best_method(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_feature就是最好的那个标签的下标\n",
    "best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拥有多个特征的决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#情况，所有的特征分完后该分支下的类标签仍然不唯一，这时候要采用多数表决函数\n",
    "def majorityCnt(classList):\n",
    "    '''\n",
    "    分支下存在不同的标签，采用voting的方式\n",
    "    '''\n",
    "    #存放标签的字典\n",
    "    class_count = {}\n",
    "    #遍历该分支的所有标签\n",
    "    for vote in classList:\n",
    "        class_count[vote] = class_count.get(vote, 0) +1\n",
    "    #对class_count进行降序排序\n",
    "    #key=operator.itemgetter(1)获取列表第一个域的值\n",
    "    #reverse=True降序\n",
    "    sorted_class = sorted(class_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #sorted_class[0][0]返回分支下类别最多的哪一个\n",
    "    return sorted_class[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = [example[-1] for example in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classList.count(classList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataset, labels):\n",
    "    '''\n",
    "    产生一棵树\n",
    "    用字典表示\n",
    "    '''\n",
    "    #类标签\n",
    "    classList = [example[-1] for example in dataset]\n",
    "    #判断类标签是否相同,若相同，说明他们都属于同一个类\n",
    "    if(classList.count(classList[0]) ==len(classList)):\n",
    "        return classList[0]\n",
    "    \n",
    "    #遍历完所有的特征后，数据集中只有一个标签列,归属于同一个类\n",
    "    if(len(dataset[0]) == 1):\n",
    "        return majorityCnt(classList)\n",
    "    \n",
    "    #确定最优特征,返回下标\n",
    "    best_feature_index = choose_best_method(dataset)\n",
    "    best_feature_label = labels[best_feature_index]\n",
    "    #储存数的信息\n",
    "    myTree = {best_feature_label:{}}\n",
    "    \n",
    "    #复制类标签\n",
    "    subLabels = labels[:]\n",
    "    #删除标签中最优的标签\n",
    "    del(subLabels[best_feature_index])\n",
    "    \n",
    "    #获取最优特征坐在的列\n",
    "    best_feature_value = [example[best_feature_index] for example in dataset]\n",
    "    unique_value = set(best_feature_value)  #也就是0或者1\n",
    "    \n",
    "    #遍历每一个特征的取值\n",
    "    for value in unique_value:\n",
    "#         递归\n",
    "        myTree[best_feature_label][value] = createTree(split_dataset(dataset, best_feature_index, value), subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytree = createTree(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tree(input_tree, featurelabels, test):\n",
    "    '''\n",
    "    输入样本点得出分类的情况\n",
    "    input_tree：输入的树\n",
    "    featurelabels：特征label\n",
    "    test：测试样本\n",
    "    '''\n",
    "    #获取树中的第一个节点\n",
    "    first_node = list(input_tree.keys())[0]\n",
    "    second_tree = input_tree[first_node]\n",
    "    #第一个特征对应的索引值\n",
    "    feature_index = featurelabels.index(first_node)\n",
    "    #遍历所有的取值\n",
    "    for key in second_tree.keys():\n",
    "        if(test[feature_index] == key):\n",
    "            #判断是否还是字典类型\n",
    "            if(type(second_tree[key]).__name__ == \"dict\"):\n",
    "                #如果是字典类型,继续分支\n",
    "                classLabel = classify_tree(second_tree[key], featurelabels, test)\n",
    "            else:\n",
    "                #只有叶子节点\n",
    "                classLabel = second_tree[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_tree(mytree, labels, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_tree(mytree, labels, [1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树的存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeTree(input_tree, filename):\n",
    "    #打开文件\n",
    "    file = open(filename, 'wb')\n",
    "    #将决策树写进文件中\n",
    "    pickle.dump(input_tree, file)\n",
    "    #关闭文件\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tree(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "storeTree(mytree, 'mytree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = load_tree('mytree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_tree(mt, labels, [1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "data, labels = shuffle(data, labels)\n",
    "train_data = data[0:140]\n",
    "test_data = data[140:-1]\n",
    "train_labels = labels[0:140]\n",
    "test_labels = labels[140:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_d = dtree.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = classification_report(pre_d, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       1.00      0.75      0.86         4\n",
      "\n",
      "   micro avg       0.89      0.89      0.89         9\n",
      "   macro avg       0.89      0.92      0.89         9\n",
      "weighted avg       0.93      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00         4\n",
    "           1       0.75      1.00      0.86         3\n",
    "           2       1.00      0.50      0.67         2\n",
    "           \n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00         3\n",
    "           1       0.67      1.00      0.80         2\n",
    "           2       1.00      0.75      0.86         4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
