{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataMat = np.mat([[1. ,2.1],\n",
    "        [2. ,1.1],\n",
    "        [1.3,1. ],\n",
    "        [1. ,1. ],\n",
    "        [2. ,1. ]])\n",
    "    classLabel = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return dataMat, classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat, classLabel = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1. , 2.1],\n",
       "        [2. , 1.1],\n",
       "        [1.3, 1. ],\n",
       "        [1. , 1. ],\n",
       "        [2. , 1. ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, -1.0, -1.0, 1.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMat, dimen, thre_val, thre_eq):\n",
    "    '''\n",
    "    单层决策树的过滤函数\n",
    "    '''\n",
    "    m, n = dataMat.shape\n",
    "    retArray = np.ones((m, 1))   #初步设置都是分类正确的\n",
    "    \n",
    "    #决策树小于的分支\n",
    "    if(thre_eq == \"lt\"):\n",
    "        #小于的分支里面通过阈值设置不同的分支\n",
    "        retArray[dataMat[0,dimen] <= thre_val] = -1.0\n",
    "        \n",
    "    #决策树大于的分支\n",
    "    else:\n",
    "        retArray[dataMat[0,dimen] > thre_val] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataMat, classLabel, D):\n",
    "    '''\n",
    "    D是指数据集之前w\n",
    "    '''\n",
    "    dataMat = np.mat(dataMat)\n",
    "    classLabel = np.mat(classLabel).T\n",
    "    m, n = dataMat.shape\n",
    "    \n",
    "    #步长区间的总数,分成10个空间\n",
    "    num_step = 10.0\n",
    "    #最优决策树信息\n",
    "    best_Tree = {}\n",
    "    #单层决策树的预测结果\n",
    "    bestClassEst = np.mat(np.zeros((m, 1)))\n",
    "    \n",
    "    #最小错误率初始化为无穷，用于后面错误率的比较\n",
    "    min_error = np.float(\"inf\")\n",
    "    \n",
    "    #三个循环，1、遍历特征值 2、步长  3、大于或小于\n",
    "    for i in range(n):\n",
    "        #该特征中的最大值和最小值\n",
    "        range_min = dataMat[:,i].min()\n",
    "        range_max = dataMat[:,i].max()\n",
    "        \n",
    "        #计算每个步长空间的大小\n",
    "        step_size = (range_max-range_min) / num_step\n",
    "        for j in range(-1, np.int(num_step)+1):     #比总的区间大没有关系吗\n",
    "            #两种阈值的过滤形式\n",
    "            for inequal in [\"lt\", \"gt\"]:\n",
    "                #阈值计算\n",
    "                thre_val = range_min + np.float(j)*step_size\n",
    "                #调用上面那个函数进行预测\n",
    "                predict_val = stumpClassify(dataMat, i, thre_val, inequal)\n",
    "                \n",
    "                #初始化错误向量\n",
    "                errArray = np.ones((m, 1))\n",
    "                #分类错误的是1，分类正确的是0\n",
    "                errArray[predict_val == classLabel] = 0\n",
    "                \n",
    "                #计算加权错误率,即正确分类的样本点权重为0，错误分类的样本点权重为下面\n",
    "                weight_error = D.T*errArray  #(1,5),(5,1) = (1,1)\n",
    "                \n",
    "#                 print(\"split: dim %d, thresh %.2f,thresh inequal: %s, the weighted error is %.3f\" %(i,thre_val,inequal,weight_error))\n",
    "                \n",
    "                #如果错误率小于当前最小的错误率，把最小的错误率设为当前d \n",
    "                print(weight_error[0,0])\n",
    "                if(weight_error[0,0] < min_error):\n",
    "                    min_error = weight_error\n",
    "                    bestClassEst = predict_val.copy()\n",
    "                    best_Tree['dim'] = i\n",
    "                    best_Tree['thre_val'] = thre_val\n",
    "                    best_Tree['ineq'] = inequal\n",
    "    \n",
    "    #返回最佳单决策树的字典、错误率和预测输出结果             \n",
    "    return best_Tree, min_error, bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.4]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoost(dataMat, classLabel, numIt = 40):\n",
    "    '''\n",
    "    adaboost算法\n",
    "    '''\n",
    "    #弱分类器信息表\n",
    "    weakClassArr = []\n",
    "    m, n = dataMat.shape\n",
    "    #初始化权重\n",
    "    D = np.ones((m, 1))/m\n",
    "    #累计估计值向量\n",
    "    aggClassEst = np.mat((m, 1))\n",
    "    \n",
    "    #迭代次数\n",
    "    for i in range(numIt):\n",
    "        bestStump,error, classEst = buildStump(dataMat, classLabel, D)\n",
    "        #求系数alpha\n",
    "        alpha = np.float(0.5*math.log((1.0-error)/(np.max(error, 1e-16))))\n",
    "        bestStump[\"alpha\"] = alpha\n",
    "        #将决策树存入到弱分类器中\n",
    "        weakClassArr.append(bestStump)\n",
    "        #更新权值D\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D/sum(D)\n",
    "        \n",
    "        #累加当前单层决策树的加权预测值\n",
    "        aggClassEst += alpha *classEst\n",
    "        \n",
    "        #求出错误分类的样本点个数\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabel).T, np.ones((m, 1)))\n",
    "        \n",
    "        #计算错误率\n",
    "        rate = sum(aggErrors)/m\n",
    "        \n",
    "        if rate == 0.0:\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-124a8728ffd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0madaBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-150-c27e76731c6b>\u001b[0m in \u001b[0;36madaBoost\u001b[1;34m(dataMat, classLabel, numIt)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#迭代次数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumIt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mbestStump\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassEst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildStump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m#求系数alpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-8d5cf8c9843c>\u001b[0m in \u001b[0;36mbuildStump\u001b[1;34m(dataMat, classLabel, D)\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;31m#如果错误率小于当前最小的错误率，把最小的错误率设为当前d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                     \u001b[0mmin_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mbestClassEst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "dataMat, classLabel = load_dataset()\n",
    "adaBoost(dataMat, classLabel, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
